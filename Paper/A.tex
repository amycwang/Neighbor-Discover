\section{Partially-Connected Networks}
\label{PCN}



%background and instances
A practical scenario is that in a network,
all the nodes are partially connected with each other.
A node can sense a rang

%density function and expectation of the neighbor number
In a partially-connected network for $\forall$ node $u_i$, 
its position coordinate $(x_i,y_i)$
obeys a certain probability distribution depending on the 
characteristic of the network, with the density function as :
$$f(x,y)=
\begin{cases}
\varphi(x,y)& (x,y)\in D\\
0& (x,y)\notin D
\end{cases}$$
where $D$ is the network covering area.

For $\forall$ node $u_i (x_i,y_i)$, its sensing range area $R_i$ can be formulated as:
$$
(x-x_i)^2+(y-y_i)^2 \leq r^2
$$
where $r$ is the the furthest detection distance.

Thus, we can obtain the expectation neighbor number of node $u_i$ as :
$$
NB(u_i) = N\iint_{R_i} f(x,y)\,dx\,dy - 1.
$$

We ignore the boundary area of the network and assume the
nodes in the network is of an enormous quantity, so the 
expectation neighbors can be formulated as:
$$
NB(u_i) = N\iint_{R_i} \varphi(x,y)\,dx\,dy.
$$

Note that, when the network area is far more larger than the
sensing area of the nodes, we can approximately get:
$$
NB(u_i) = N\pi r^2 \varphi(x,y).
$$




%Alano
Then we propose \textbf{Alano}, a randomized neighbor discovery algorithm. 
We describe the algorithm for $\forall$ node $u_i$ in Alg. \ref{Alano}.
Alano algorithm indicates that what probability for a node choose to turn to  
tramisitting state or listening state is determined
by the expectation neighbor number varying from node to node.


\begin{algorithm}
\caption{Alano Algorithm}
\label{Alano}
\begin{algorithmic}[1]
\STATE $\hat{n_i} = N\iint_{R_i} \varphi(x,y)\,dx\,dy$;
\STATE $p_t^i = \frac{1}{\hat{n_i}}$;
\WHILE {$True$}
	\STATE A random float $\epsilon \in (0,1)$;
   	 \IF{$\epsilon < p_t$}
    		\STATE Transmit a message containing node information of $u_i$;
	\ELSE
    		\STATE Listen on the channel and decode the node information if receive a message successfully;
	\ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}

In the following section \ref{uniform}, we first consider a general situation that the nodes
in the network are uniform distributed. We derive a proof that the probability
chosen in Alano is the optimal one and show the bounded latency will not 
be much larger than its expectation. Then in the section  \ref{normal} we describe a more
common situation that the nodes in the network obey normal distribution, we present a 
approximately analysis that the discovery latency will not be much larger than uniform distribution.


\subsection{Uniform Distribution}
\label{uniform}
%background
There are a part of partially-connected networks obeying uniform distribution. 
For instance, consider there is a  wireless sensor network carrying out a task of
measuring temperature and humidity in a target area, 
thus the sensors are supposed to be evenly deployed and the density function can be 
formulated as:
$$f(x)=
\begin{cases}
\frac{1}{A}& (x,y)\in D\\
0& (x,y)\notin D
\end{cases}$$
where $A$ is the dimension of $D$.

Every node in the network has the same expectation 
of neighbor number and transmit with the same probability as:
$$
\hat{n} = \frac{N\pi r^2}{A}, \quad p_t = \frac{1}{\hat{n}}=\frac{A}{N\pi r^2}.
$$  

According to Alano, the probability that node $u_i$ discover a specific
neighbor successfully in a time slot can be formulated as:
$$
p_s = p_t{(1-p_t)}^{\hat{n}-1}.
$$
Let:
$$
p_s' = {(1-p_t)}^{\hat{n}-1}-(\hat{n}-1)p_t{(1-p_t)}^{\hat{n}-2}=0.
$$
It is easy to confirm that  when
$$p_t=\frac{1}{\hat{n}}.$$ 
$p_s$ gets the maximum value:
$$p_s = \frac{1}{\hat{n}}{(1-\frac{1}{\hat{n}})}^{\hat{n}-1} \approx \frac{1}{\hat{n}e}.$$

Thus we can conclude that the probability chosen in Alano
to transmit is the optimal one. 

Next we analyse the expectation latency for a node to discover all its 
neighbors. We denote $W_j$ to be a random variable that a new neighbor
is discovered after the node has discovered $(j-1)$ neighbors, which follows 
Geometric distribution with parameter $p(j): p(j)=(\hat{n}-j+1)p_s$. Then the expectation
of $W_j$ is computed as:
$$
E[W_j]=\frac{1}{p(j)}=\frac{1}{(\hat{n}-j+1)p_s}
$$

The expectation time latency of discovering all the neighbors can be formulated as:
$$
E(W_j) = \sum_{j=1}^{\hat{n}}\frac{1}{p_s}H_n \approx ne(lnn + O(1)) = O(nlnn).
$$
where $H_n$ is the $n$-th Harmonic number, i.e.,
$H_n = lnn + O(1)$.

We get the expectation discovery lantecy is within O(nlogn) and then we
show the bounded latency will not be much larger than its expectation.

%To be modified later
%%
If $W_i$ is given, the value of $W_j$ will not be affected for $i<j$. That is, for $i\ne j$, $W_i$ and $W_j$ are independent and they satisfy $P(W_j=w_j|W_i=w_i)=P(W_j=w_j)$. Since $W_j$ follows Geometric distribution, and $Var[W_j]=\frac{1-p_j}{p_j^2}$, the variance of $W$ is
\begin{displaymath}
\begin{split}
 Var[W] %& =Var[\sum_{j=1}^{p_nN}W_j]=\sum_{j=1}^{p_nN}Var[W_j]+\sum_{j\ne k}Cov[W_j,W_k] \\
 =\sum_{j=1}^{n}Var[W_j]
%=\frac{1}{p_{suc}^2}\sum_{j=1}^{p_nN}\frac{1}{j^2}-\frac{1}{p_{suc}}\sum_{j=1}^{p_nN}\frac{1}{j} \\
 \le\frac{\pi^2}{6p_{suc}^2}-\frac{H_n}{p_{suc}}.
\end{split}
\end{displaymath}

With \emph{Chebyshev's inequality}, the probability that the discovery time is 2 times larger than the expectation is
\begin{displaymath}
\begin{split}
P[W\ge2E[W]]%=P[|W-E[W]|\ge E[W]]
\le\frac{Var[W]}{E[W]^2}
%&\le\frac{\frac{\pi^2}{6p_{suc}^2}-\frac{H_{p_nN}}{p_{suc}}}{\frac{H_{p_nN}^2}{p_{suc}^2}}=
\le\frac{\pi^2}{6H_{n}^2}-\frac{p_{suc}}{H_n}.
\end{split}
\end{displaymath}
For large $n$, $P[W\ge2E[W]]$ is close to 0. That is, the time for a node to find all neighbors is very likely to be smaller than $2$ times of expected latency. Therefore,
\begin{equation}
W=O(nlnn).
\end{equation}

In a word, Alano-NCD and Alano-WCD both are bounded by $O(nlnn)$.

%%



%*****************



The expectation neighbor number of each node:





\subsection{Normal Distribution}
\label{normal}

For , denote the neighbors of 

$$
p_{suc} = (1-p_t^i)p_t^{ij}\prod_{ k=1}^{\hat{n_i}, k\neq j}(1-p_t^{ik})
$$





